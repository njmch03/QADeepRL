import sys
from tqdm import tqdm
sys.path.append('OpenNMT/')
sys.path.append('../QA_env/')
import argparse
import numpy as np
import logging
import torch
import torch.autograd as autograd
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.autograd import Variable
from torch.nn import Parameter
from glob import glob
import math
from collections import OrderedDict
import time
import random
import itertools
from itertools import chain
from model import BiDAF
from evaluator import GPUF1Evaluator, F1Evaluator
from read_data import read_data, get_squad_data_filter, update_config 
from utils import *
from RL_args import parse_args
from onmt.translate.Translator import make_translator
import onmt.io
import onmt.translate
import onmt
import onmt.ModelConstructor
import onmt.modules
import onmt.opts
from datetime import datetime



def eval_model(model, trn_data, dev_data, QA_config, NMT_config, RL_config, translator):

    model.eval()

    dev_num_steps = int(math.ceil(dev_data.num_examples / (QA_config.batch_size * QA_config.num_gpus)))
    trn_num_steps = int(math.ceil(trn_data.num_examples / (QA_config.batch_size * QA_config.num_gpus)))

    evaluator = GPUF1Evaluator(QA_config, model)

    e_trn = evaluator.get_evaluation_from_batches(tqdm(trn_data.get_multi_batches(QA_config.batch_size, QA_config.num_gpus, num_steps=trn_num_steps, shuffle=True, cluster=QA_config.cluster), total=trn_num_steps), True, NMT_config, RL_config, translator)
    print(e_trn)
    e_dev = evaluator.get_evaluation_from_batches(tqdm(dev_data.get_multi_batches(QA_config.batch_size, QA_config.num_gpus, num_steps=dev_num_steps, shuffle=True, cluster=QA_config.cluster), total=dev_num_steps), True, NMT_config, RL_config, translator)

    print(e_dev)


def create_loss(log_prob, f1):

    return 0


def main(NMT_config):

    ### Load RL (global) configurations ###
    config = parse_args()

    ### Load trained QA model ###                                                                                    
    QA_checkpoint = torch.load(config.data_dir + config.QA_best_model)
    QA_config =QA_checkpoint['config']
    
    QA_mod = BiDAF(QA_config)
    if QA_config.use_gpu:
        QA_mod.cuda()
    QA_mod.load_state_dict(QA_checkpoint['state_dict'])

    ### Load SQuAD dataset ###
    data_filter = get_squad_data_filter(QA_config)

    train_data = read_data(QA_config, 'train', QA_config.load, data_filter=data_filter)
    dev_data = read_data(QA_config, 'dev', True, data_filter=data_filter)

    update_config(QA_config, [train_data, dev_data])

    print("Total vocabulary for training is %s" % QA_config.word_vocab_size)

    # from all                                                                                                                                                        
    word2vec_dict = train_data.shared['lower_word2vec'] if QA_config.lower_word else train_data.shared['word2vec']
    # from filter-out set                                                                                                                                             
    word2idx_dict = train_data.shared['word2idx']

    # filter-out set idx-vector                                                                                                                                       
    idx2vec_dict = {word2idx_dict[word]: vec for word, vec in word2vec_dict.items() if word in word2idx_dict}
    print("{}/{} unique words have corresponding glove vectors.".format(len(idx2vec_dict), len(word2idx_dict)))

    # <null> and <unk> do not have corresponding vector so random.                                                                                                    
    emb_mat = np.array([idx2vec_dict[idx] if idx in idx2vec_dict
                        else np.random.multivariate_normal(np.zeros(QA_config.word_emb_size), np.eye(QA_config.word_emb_size))
                        for idx in range(QA_config.word_vocab_size)])

    config.emb_mat = emb_mat
    config.new_emb_mat = train_data.shared['new_emb_mat']

    num_steps = int(math.ceil(train_data.num_examples / (QA_config.batch_size * QA_config.num_gpus))) * QA_config.num_epochs

    # offset for question mark
    NMT_config.max_length = QA_config.ques_size_th - 1
    NMT_config.batch_size = QA_config.batch_size
    
    ### Construct translator ###                                                                              
    translator = make_translator(NMT_config, report_score=True)
    
    ### Construct optimizer ###
    optimizer = optim.SGD(filter(lambda p: p.requires_grad, translator.model.parameters()), lr=config.lr)
    
    ### Start RL training ###
    count = 0
    QA_mod.eval()
    F1_eval = F1Evaluator(QA_config, QA_mod)
    #eval_model(QA_mod, train_data, dev_data, QA_config, NMT_config, config, translator)
    
    for i in range(config.n_episodes):
        for batches in tqdm(train_data.get_multi_batches(QA_config.batch_size, QA_config.num_gpus,
                                                     num_steps=num_steps, shuffle=True, cluster=QA_config.cluster), total=num_steps):
        
            #for n, p in translator.model.named_parameters():
            #    print(n)
            #    print(p)
                #print(p.requires_grad)

            start=datetime.now()  
            to_input(batches[0][1].data['q'], config.RL_path + config.RL_file)
        
            # obtain rewrite and log_prob 
            q, scores, loss = translator.translate(NMT_config.src_dir, NMT_config.src, NMT_config.tgt,
                                         NMT_config.batch_size, NMT_config.attn_debug)
            '''
            q, cq = ref_query(q)
            batches[0][1].data['q'] = q
            batches[0][1].data['cq'] = cq

            print(loss)
            
            translator.model.zero_grad()
            #for n, p in translator.model.named_parameters():
            #    print(n)
            #    print(p.grad)
                #print(p.requires_grad)  
           
            QA_mod(batches)

            e = F1_eval.get_evaluation(batches, False, NMT_config, config, translator)
            #print(e.f1s)
            
            loss = loss.sum() #create_loss(scores, e.f1s)
            loss.backward()
            optimizer.step()
            print("=" * 50)
            for n, p in translator.model.named_parameters():
                print(n)
                print(p.grad)
                #print(p.requires_grad)
            
            count +=1
            print(datetime.now()-start)
            '''
            break
        
        

if __name__ == "__main__":


    ### Set arguments for NMT ###
    parser = argparse.ArgumentParser(
        description='translate.py',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    onmt.opts.add_md_help_argument(parser)
    onmt.opts.translate_opts(parser)

    opt = parser.parse_args()
    opt.src ='/scratch/rjh347/RL/input.txt'                                                                                                                                                          
    opt.model = '/scratch/rjh347/output/NMT0419_model_acc_74.72_ppl_2.96_e13.pt' 
    opt.output = '/scratch/rjh347/RL/output.txt'
    opt.replace_unk = True
    main(opt)
